{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b9cf026-e64a-49ba-9409-a8f31a4955dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "github_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv'\n",
    "url = f'{github_url}?raw=1'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df = df.iloc[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "016f79d8-d927-4c31-89f4-40b0c100d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\"multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4afa6c4-36d0-42a1-b229-4c8988a2eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm = df.iloc[0].answer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec77867a-e1c2-4cb7-8e39-bf02fb12e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = embedding_model.encode(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa128a6e-8919-4ce8-ac36-b38a8fa4e72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.42"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(vector[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "517ffb6d-7f50-4dab-ba13-0191aa732443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:49<00:00,  6.01it/s]\n"
     ]
    }
   ],
   "source": [
    "def simi(record):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm =  record['answer_llm']\n",
    "\n",
    "    v_orig = embedding_model.encode(answer_orig)\n",
    "    v_llm = embedding_model.encode(answer_llm)\n",
    "\n",
    "    return v_llm.dot(v_orig)\n",
    "\n",
    "results = df.to_dict(orient='records')\n",
    "\n",
    "from tqdm import tqdm\n",
    "simu = []\n",
    "\n",
    "for record in tqdm(results_gpt4o):\n",
    "    sim = simi(record)\n",
    "    simu.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "528fcb48-aa8e-4b0d-80c5-f5d67bb4aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cosine'] = simu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ccb3cc7-dfa4-4a94-a89d-d3b619240917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    300.000000\n",
       "mean      27.495996\n",
       "std        6.384742\n",
       "min        4.547923\n",
       "25%       24.307844\n",
       "50%       28.336870\n",
       "75%       31.674309\n",
       "max       39.476013\n",
       "Name: cosine, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cosine'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83999a45-363e-463c-92c5-84427e2e45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "norm = np.sqrt(( df['cosine'] *  df['cosine']).sum())\n",
    "v_norm = df['cosine'] / norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a96ad91e-ae12-40c1-8f6d-6014006d977b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    300.000000\n",
       "mean       0.056244\n",
       "std        0.013060\n",
       "min        0.009303\n",
       "25%        0.049722\n",
       "50%        0.057964\n",
       "75%        0.064790\n",
       "max        0.080749\n",
       "Name: cosine, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3dc35eed-5ce4-47fe-9fcb-9d636afaa90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m2 packages\u001b[0m \u001b[2min 86ms\u001b[0m\u001b[0m                                          \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 10ms\u001b[0m\u001b[0m                                               \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m                                  \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrouge\u001b[0m\u001b[2m==1.0.1\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!uv pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "055c42e9-a8f2-4184-b192-a8ff73b053a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 0.45454545454545453,\n",
       "  'p': 0.45454545454545453,\n",
       "  'f': 0.45454544954545456},\n",
       " 'rouge-2': {'r': 0.21621621621621623,\n",
       "  'p': 0.21621621621621623,\n",
       "  'f': 0.21621621121621637},\n",
       " 'rouge-l': {'r': 0.3939393939393939,\n",
       "  'p': 0.3939393939393939,\n",
       "  'f': 0.393939388939394}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "rouge_scorer = Rouge()\n",
    "\n",
    "scores = rouge_scorer.get_scores(df['answer_llm'][10], df['answer_orig'][10])[0]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52936fcf-7f69-4fd2-a7d6-2508a66fc62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35490034990035496"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scores['rouge-1']['f'] + scores['rouge-2']['f'] + scores['rouge-l']['f']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3dda6a5-7117-4cba-8445-a802e68f2c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07288173149369313\n"
     ]
    }
   ],
   "source": [
    "scores = rouge_scorer.get_scores(df['answer_llm'], df['answer_orig'])[0]\n",
    "rouge_1 = scores['rouge-1']['f']\n",
    "rouge_2 = scores['rouge-2']['f']\n",
    "rouge_l = scores['rouge-l']['f']\n",
    "rouge_avg = (rouge_1 + rouge_2 + rouge_l) / 3\n",
    "print(rouge_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ecbc4-cfb5-4e0f-aaff-efd0935b2252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
